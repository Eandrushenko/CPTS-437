{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eandrushenko/CPTS-437/blob/master/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "livSmgt291zf",
        "colab_type": "text"
      },
      "source": [
        "Elijah Andrushenko\n",
        "CPTS 437\n",
        "1-17-2019\n",
        "Introduction to Machine Learning\n",
        "\n",
        "1. 10 Features\n",
        "1) Font Color - One font is grey while the other is black.\n",
        "2) Font Size - The sizes are slightly different and how big each letter is relative to the other letters differ.\n",
        "3) Character Spacing - The spacing for my letters are very close compared to Sam's letter spacing.\n",
        "4) The Os - My Os are closer to an ellipse while Sam's are similiar to a circle.\n",
        "5) The Us - My Us have a little part at the end while Sam.s are more like a horseshoe.\n",
        "6) the Gs - My Gs are similiar to cursive Gs, and Sam's are simpler.\n",
        "7) Smoothness - My font type is smoother while Sam's are more blocky.\n",
        "8) Word Spacing - The Spacing from one word to another for me are closer compared to Sam's word spacing.\n",
        "9) Character Thickness - My letters are thicker than Sam's letters.\n",
        "10) The Ss - My Ss are squiggly while Sam's tend to be blocky and some look like 5s.\n",
        "\n",
        "2. See Photo Attachment--> (http://prntscr.com/m8pucx)\n",
        "\n",
        "3. Entropy(3, 3) = 1\n",
        "\n",
        "F1 = (1/3)(Entropy(1,1))+(1/3)(Entropy(2, 0))+(1/3)(Entropy(0, 2)) = 1/3\n",
        "F1 = 1 - 1/3 = 2/3 = 0.67\n",
        "\n",
        "F2 = (1/2)(Entropy(2, 1))+(1/2)(Entropy(1, 2))+0(Entropy(0,0)) = 0.92\n",
        "F2 = 1 - 0.92 = 0.08\n",
        "\n",
        "F3 = (1/3)(Entropy(1, 1))+0(Entropy(0, 0))+(2/3)(Entropy(2,2)) = 1\n",
        "F3 = 1 - 1 = 0\n",
        "\n",
        "F1 would be the chosen root of the decision tree since it has the highest information gain at 0.67.\n",
        "\n",
        "\n",
        "\n",
        "4. To determine if a decision tree has over fit for its given training data we can calculate the ratio of (test data / training data) accuracy, at any size of the tree. The closer to 1 this ratio is, then the more fit the training data is with the test data. The further from 1 this ratio is, then the more overfit it is for the training data.\n",
        "Based on the graph and my explanation above, The optimal size decision tree size would be 10, since at 10 nodes we have the highest accuracy for our test data and the ratio at 10 nodes would be (0.75 accuracy for test data/ 0.75 accuracy for training data) = 1, so it is a perfect fit, At higher numbers of nodes our test accuracy decreases and our ratio diverges away from 1.\n",
        "\n",
        "5. I wasn't sure how to modify your code, even took an extra day to try to figure it out no luck....I was going to start from scratch but theres no time at this point. If the test data was more than 50% accurate then it is better than random guess since there is a 50/50 shot at getting the answer right, so if it does better than that then it must be better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0XLC5QPqvZ",
        "colab_type": "code",
        "outputId": "645cd6d3-46a3-46a5-8cc6-3d8267433d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#SETUP\n",
        "#Code taken from Dr. Cook to upload har.csv\n",
        "import math\n",
        "import collections\n",
        "import numpy\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "\n",
        "# Read a data file in csv format, separate into features and class arrays\n",
        "def read_data():\n",
        "  data = numpy.loadtxt(fname='/content/gdrive/My Drive/Colab Notebooks/har.csv', delimiter=',')\n",
        "  X = data[:,:-1] # features are all values but the last on the line\n",
        "  y = data[:,-1] # class is the last value on the line\n",
        "  return X, y\n",
        "\n",
        "data, answer = read_data()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1LcMCXrgde_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Part 1, replacing gini measure with Information Gain Measure\n",
        "#This was also provided by Dr. Cook\n",
        "def Entropy(pos, neg):\n",
        "  pf = pos/float(pos + neg)\n",
        "  nf = neg/float(pos + neg)\n",
        "  if (pf == 0):\n",
        "    term1 = 0\n",
        "  else:\n",
        "    term1 = -pf * math.log(pf, 2.0)\n",
        "  if (nf == 0):\n",
        "    term2 = 0\n",
        "  else:\n",
        "    term2 = -nf * math.log(nf, 2.0)\n",
        "  entropy = term1 + term2\n",
        "  return entropy\n",
        "\n",
        "def Gain(pos, neg, splits):\n",
        "  start = Entropy(pos, neg)\n",
        "  #print(start)\n",
        "  mysum = start\n",
        "  for feature in splits:\n",
        "    #print(feature)\n",
        "    size = (feature[0] + feature[1]) / (pos+neg)\n",
        "    feature_entropy = Entropy(feature[0], feature[1])\n",
        "    #print(feature_entropy)\n",
        "    mysum -= size*feature_entropy\n",
        "    return mysum\n",
        "  \n",
        "#print(Entropy(3, 3))\n",
        "#print(Gain(3, 3, [[1, 1], [0, 2], [2, 0]]))\n",
        "\n",
        "# Calculate the Gini index for a subset of the dataset\n",
        "def gini_index(groups, classes):\n",
        "   # count all samples at split point\n",
        "   num_instances = float(sum([len(group) for group in groups]))\n",
        "\n",
        "   gini = 0.0 # sum weighted Gini index for each group\n",
        "   for group in groups:\n",
        "      size = float(len(group))\n",
        "      if size == 0: # avoid divide by zero\n",
        "         continue\n",
        "      score = 0.0\n",
        "      # score the group based on the score for each class\n",
        "      for class_val in classes:\n",
        "         p = [row[-1] for row in group].count(class_val) / size\n",
        "         score += p * p\n",
        "      # weight the group score by its relative size\n",
        "      gini += (1.0 - score) * (size / num_instances)\n",
        "   return gini\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGndZsqTiKyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create child splits for a node or make a leaf node\n",
        "def split(node, max_depth, depth):\n",
        "   left, right = node['groups']\n",
        "   del(node['groups'])\n",
        "   # check for a no split\n",
        "   if not left or not right:\n",
        "      node['left'] = node['right'] = create_leaf(left + right)\n",
        "      return\n",
        "   # check for max depth\n",
        "   if depth >= max_depth:\n",
        "      node['left'], node['right'] = create_leaf(left), create_leaf(right)\n",
        "      return\n",
        "   node['left'] = select_attribute(left)\n",
        "   split(node['left'], max_depth, depth+1)\n",
        "   node['right'] = select_attribute(right)\n",
        "   split(node['right'], max_depth, depth+1)\n",
        "    \n",
        "\n",
        "\n",
        "# split the dataset based on an attribute and attribute value\n",
        "def test_split(index, value, dataset):\n",
        "   left, right = list(), list()\n",
        "   for row in dataset:\n",
        "      if row[index] < value:\n",
        "         left.append(row)\n",
        "      else:\n",
        "         right.append(row)\n",
        "   return left, right\n",
        "\n",
        "\n",
        "# Select the best split point for a dataset\n",
        "def select_attribute(dataset):\n",
        "   class_values = list(set(row[-1] for row in dataset))\n",
        "   b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "   for index in range(len(dataset[0])-1):\n",
        "      for row in dataset:\n",
        "         groups = test_split(index, row[index], dataset)\n",
        "         gini = gini_index(groups, class_values)\n",
        "         if gini < b_score:\n",
        "            b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "   return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og2otRNyigNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a leaf node class value\n",
        "def create_leaf(group):\n",
        "   outcomes = [row[-1] for row in group]\n",
        "   return max(set(outcomes), key=outcomes.count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzHKFKpGiiA5",
        "colab_type": "code",
        "outputId": "5334c447-a800-4ee8-81a2-70325e03e492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Build a decision tree\n",
        "def build_tree(train, max_depth):\n",
        "   root = select_attribute(train)\n",
        "   split(root, max_depth, 1)\n",
        "   return root\n",
        "  \n",
        "  \n",
        "# Print a decision tree\n",
        "def print_tree(node, depth=0):\n",
        "   if depth == 0:\n",
        "      print('Tree:')\n",
        "   if isinstance(node, dict):\n",
        "      print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
        "      print_tree(node['left'], depth+1)\n",
        "      print_tree(node['right'], depth+1)\n",
        "   else:\n",
        "      print('%s[%s]' % ((depth*' ', node)))\n",
        "      \n",
        "      \n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "   dataset = [[2.771244718,1.784783929,0], [1.728571309,1.169761413,0],\n",
        "              [3.678319846,2.812813570,0], [3.961043357,2.619950320,0],\n",
        "              [2.999208922,2.209014212,0], [7.497545867,3.162953546,1],\n",
        "              [9.00220326, 3.339047188,1], [7.444542326,0.476683375,1],\n",
        "              [10.12493903,3.234550982,1], [6.642287351,3.319983761,1]]\n",
        "   tree = build_tree(dataset, 1)\n",
        "   print_tree(tree)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree:\n",
            "[X1 < 6.642]\n",
            " [0]\n",
            " [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4-i4FmUj9u5",
        "colab_type": "code",
        "outputId": "5a4b3501-36a6-4732-ab03-ad4a9da8914e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Make a prediction with a decision tree\n",
        "def predict(node, row):\n",
        "   if row[node['index']] < node['value']:\n",
        "      if isinstance(node['left'], dict):\n",
        "         return predict(node['left'], row)\n",
        "      else:\n",
        "         return node['left']\n",
        "   else:\n",
        "      if isinstance(node['right'], dict):\n",
        "         return predict(node['right'], row)\n",
        "      else:\n",
        "         return node['right']\n",
        "\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "   dataset = [[2.771244718,1.784783929,0], [1.728571309,1.169761413,0],\n",
        "              [3.678319846,2.812813570,0], [3.961043357,2.619950320,0],\n",
        "              [2.999208922,2.209014212,0], [7.497545867,3.162953546,1],\n",
        "              [9.00220326, 3.339047188,1], [7.444542326,0.476683375,1],\n",
        "              [10.12493903,3.234550982,1], [6.642287351,3.319983761,1]]\n",
        "   tree = build_tree(dataset, 3)\n",
        "   print_tree(tree)\n",
        "   for row in dataset:\n",
        "      prediction = predict(tree, row)\n",
        "      print('Predicted=%d, Ground truth=%d' % (prediction, row[-1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree:\n",
            "[X1 < 6.642]\n",
            " [X1 < 2.771]\n",
            "  [X1 < 1.729]\n",
            "   [0]\n",
            "   [0]\n",
            "  [X1 < 2.771]\n",
            "   [0]\n",
            "   [0]\n",
            " [X1 < 7.498]\n",
            "  [X1 < 7.445]\n",
            "   [1]\n",
            "   [1]\n",
            "  [X1 < 7.498]\n",
            "   [1]\n",
            "   [1]\n",
            "Predicted=0, Ground truth=0\n",
            "Predicted=0, Ground truth=0\n",
            "Predicted=0, Ground truth=0\n",
            "Predicted=0, Ground truth=0\n",
            "Predicted=0, Ground truth=0\n",
            "Predicted=1, Ground truth=1\n",
            "Predicted=1, Ground truth=1\n",
            "Predicted=1, Ground truth=1\n",
            "Predicted=1, Ground truth=1\n",
            "Predicted=1, Ground truth=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir5t4jYGj-8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}